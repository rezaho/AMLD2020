{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9x6-u2lxYkP"
   },
   "source": [
    "# Cross lingual processing and Transfer Learning using multi-linguale embedding\n",
    "\n",
    "On this notebook, we will work on a multilingual dataset containing sentences in six languages: english, dutch, spanish, russian, arabic and turkish. Every sentence of every language comes along a with sentiment label indicating *positive* or *negative* content. There is no sentence overlap between idioms. \n",
    "\n",
    "Working with the LASER multilinguale representation, we directly provide the sentence embedding for all languages. Every sentence is represented by a 1024 dimensional vector indicating its position in LASER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGG1H0Vk2gWl"
   },
   "source": [
    "# Loading data from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qnXLnDSxFCL"
   },
   "outputs": [],
   "source": [
    "#Let's download the dataset (if not done already) and define path\n",
    "import os\n",
    "!git clone https://github.com/ioannispartalas/CrossLingual-NLP-AMLD2020.git\n",
    "#With this command, the path to the data is \n",
    "workdir = './CrossLingual-NLP-AMLD2020/'\n",
    "os.environ[\"WORKDIR\"] = workdir\n",
    "#Please check if this correct, otherwise correct path_to_data\n",
    "!ls $WORKDIR/data/laser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5uVWdjc4US0"
   },
   "source": [
    "The dataset is made of numpy files:\n",
    "```\n",
    "'en_laser_train.npy'\n",
    "'en_laser_test.npy'\n",
    "'nl_laser_test.npy'\n",
    "...\n",
    "```\n",
    "containing respectively training and test set for every language. \n",
    "\n",
    "Corresponding labels are stored in \n",
    "```\n",
    "en_train_labels_adan.txt\n",
    "en_test_labels_adan.txt\n",
    "nl_laser_train.npy\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CXfmDUITycJ7"
   },
   "source": [
    "# Importing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLIhEatowOB4"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sys.path.insert(1, workdir)\n",
    "\n",
    "from src.utils import load_training_languages, model_evaluation, get_statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldZjtvZdmEMz"
   },
   "source": [
    "The 3 following utility functions will be used in this notebook:\n",
    "\n",
    "- ```\n",
    "model_evaluation(model, [languages])\n",
    "```: evaluate the ```model``` over list of ```languages```. Returns [F1](https://en.wikipedia.org/wiki/F1_score) score, more suited for imbalanced dataset and [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) to analyse model outputs in details.\n",
    "- ```x_train, y_train = load_training_languages([languages])```: Returns concatenated features and labels for languages specified in ```languages```.\n",
    "- ```get_statistics([languages]```: print out class population for languages specified in ```languages```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9q6Ce_pyiTP"
   },
   "source": [
    "# Dataset statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGkvj85TxuCY"
   },
   "source": [
    "The multilingual dataset consists in 6 different languages: english (```en```), spanish (`es`), dutch (`nl`), russian (`ru`), arabic (`a`r) and turkish (`tr`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AloTmSlbk-Lo"
   },
   "outputs": [],
   "source": [
    "all_languages = ['en','es','nl','ru','ar','tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AafUgnCfjUdw"
   },
   "outputs": [],
   "source": [
    "get_statistics(all_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7QUqPAIW0M1j"
   },
   "source": [
    "#Few Shot Learning\n",
    "While learning a language classification model generally requires abundance of training materials, it happens frequently that some languages are systematically under representated, leading to poor prediction performance. \n",
    "\n",
    "In that situation, using a common language representation such as LASER permits to increase the training data by adding to the initial (small) set, (possibly larger) dataset from other languages. \n",
    "\n",
    "As shown in figure below, poplulating the training space increases the chances to accurately determine the decision function.  \n",
    "\n",
    "![Few Shot Learning](https://upload.wikimedia.org/wikipedia/commons/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png)\n",
    "\n",
    "In the following, we are going to experiment the Few Shot Learning concepts by training and testing classifier on different combinations of languague."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YjsJKOSmpEo0"
   },
   "source": [
    "Let's train a [Logistic Regression](https://fr.wikipedia.org/wiki/R%C3%A9gression_logistique) (a linear classifier) on russian, and look at the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZqEBpoKS-7pc"
   },
   "outputs": [],
   "source": [
    "x_train,y_train = load_training_languages(['ru'])\n",
    "lr = LogisticRegression(C = 10,max_iter = 200,random_state = 1).fit(x_train,y_train)\n",
    "_ = model_evaluation(lr, ['ru'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wim0DcAopcNL"
   },
   "source": [
    "The overall performance is not fantastic. Could we do better? Let's add more languages to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-IH0vRjeaal"
   },
   "outputs": [],
   "source": [
    "x_train,y_train = load_training_languages(all_languages)\n",
    "lr = LogisticRegression(C = 10,max_iter = 200,random_state = 1).fit(x_train,y_train)\n",
    "_ = model_evaluation(lr, ['ru'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msQlJTsC_U6L"
   },
   "source": [
    "The F1 score has improved by 0.1! Quite impressive.\n",
    "\n",
    "Same operation with turkish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZB4oz2LD72lj"
   },
   "outputs": [],
   "source": [
    "x_train,y_train = load_training_languages(['tr'])\n",
    "lr = LogisticRegression(C = 10,random_state = 1).fit(x_train,y_train)\n",
    "_ = model_evaluation(lr, ['tr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0GZ3DlLYALnp"
   },
   "source": [
    "The F1 score is now quite low. Small dataset, data quality, language complexity may explain the poor performance.\n",
    "\n",
    "Fair enough, let's use all available languages to improve our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pU1No16mLALv"
   },
   "outputs": [],
   "source": [
    "x_train,y_train = load_training_languages(all_languages)\n",
    "lr = LogisticRegression(C = 10,max_iter = 200,random_state = 1).fit(x_train,y_train)\n",
    "_ = model_evaluation(lr, ['tr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tUaxHSMFBUvC"
   },
   "source": [
    "No improvement... Maybe another combination of languages leads to different results. What happen if we remove spanish and russian from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4vnNbolBWhG"
   },
   "outputs": [],
   "source": [
    "x_train,y_train = load_training_languages(['ar','tr','nl','en'])\n",
    "lr = LogisticRegression(C = 10,max_iter = 200,random_state = 1).fit(x_train,y_train)\n",
    "_ = model_evaluation(lr, ['tr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcFDEuQtpoFL"
   },
   "source": [
    "Better! Apparently spanish and russian were perturbing the model for turkish language.\n",
    "\n",
    "Could we imagine a more systematic source language selection to optimize performance on a specific target language? (Beware that the test set of the target language cannot be used to perform this selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZvAUeCZosnce"
   },
   "source": [
    "#Non linear model\n",
    "Until now we have used Logisitic Regression. However more complex models, such as [multi layer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCA27E34vlHO"
   },
   "outputs": [],
   "source": [
    " from sklearn.neural_network import MLPClassifier\n",
    " mlp = MLPClassifier(solver='lbfgs', \n",
    "                     hidden_layer_sizes=(16),\n",
    "                     activation = 'relu',\n",
    "                     alpha=1e-3,\n",
    "                     max_iter = 50,\n",
    "                     early_stopping =True,\n",
    "                     validation_fraction = 0.2, \n",
    "                     random_state=1)\\\n",
    "      \n",
    " _ = model_evaluation(mlp.fit(x_train,y_train),['ru'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWVM12v_RXG3"
   },
   "source": [
    "or [extreme gradient boosting](https://en.wikipedia.org/wiki/XGBoost) (xgboost) are obviously possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUaqSmH4Pvni"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "boost = xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\",max_depth =5, random_state=42)\n",
    "_ = model_evaluation(boost.fit(x_train,y_train),['ru'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JvX_liTERnBB"
   },
   "source": [
    "What can we conclude from the above results?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de Copie de sklearn_LASER_cross_language_embd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
